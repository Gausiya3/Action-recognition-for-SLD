# Action Recognition for Sign Language Detection

> **Abstract** : This project innovatively combines the precision of MediaPipe Holistic Keypoints and the temporal dynamics capture of Long Short-Term Memory (LSTM) layers. The primary focus is on real-time action recognition, particularly in sign language. Leveraging the spatial information extracted by MediaPipe, the system utilizes an LSTM-based model for nuanced understanding of the temporal dynamics in sign language actions. The integration enables the system to predict sign language actions in real-time from video sequences, providing immediate feedback for enhanced communication. This project not only advances real-time action recognition technologies but also signifies a breakthrough in fostering accessibility and inclusivity, especially for the hearing-impaired community.

### Project Members 
1. ANSARI GAUSIYA KHATOON HAFIZURREHMAN  [ Team Leader ] 
2. KHAN CEZZANE AKHTAR 
3. GURNULE ATHARVA CHANDRAKANT 
4. KALZUNKAR OJAS ANIL 

### Project Guides
1. PROF. NARGIS SHAIKH (ECS)  [ Primary Guide ] 

### Subject Details
- Class : BE (AI&DS) Div A - 2023-2024
- Subject : Major Project-2 (A) (MP 2 (A) (R19))
- Project Type : Major Project

### Platform, Libraries and Frameworks used
1. Mediapipe holistics
2. Opencv
3. Scikit- learn
4. TensorFlow
5. Matplotlib

### References
[1] “OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields ” Z Cao, 
G Hidalgo, T Simon, S-E Wei, Y Sheikh. 
[2] Nguyen, T., & Bi, X. (2018). Sign Language Recognition using Computer Vision. In IEEE 
International Conference on Robotics and Automation (ICRA). 
[3] Du, Y., et al. (2020). Sign Language Recognition with Deep Learning: An Overview. In IEEE 
Transactions on Neural Networks and Learning Systems.
